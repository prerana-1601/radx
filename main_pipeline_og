# main_pipeline.py
'''
import os
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import cv2
from rag.llm_chain import get_qa_chain, _extract_text
from rag.schemas import PneumoniaInfo
from rag.llm_chain import generate_radiology_report
from api.gradcam import GradCAM
#from GradCAM import generate_heatmap
#from GradCAM import generate_report


# ------------------
# Grad-CAM Hook
# ------------------

class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        self.hook_layers()

    def hook_layers(self):
        def forward_hook(module, input, output):
            self.activations = output.detach()

        def backward_hook(module, grad_in, grad_out):
            self.gradients = grad_out[0].detach()

        self.target_layer.register_forward_hook(forward_hook)
        self.target_layer.register_backward_hook(backward_hook)

    def generate(self, class_idx):
        pooled_gradients = torch.mean(self.gradients, dim=[0, 2, 3])
        activations = self.activations[0]

        for i in range(len(pooled_gradients)):
            activations[i, :, :] *= pooled_gradients[i]

        heatmap = torch.mean(activations, dim=0).cpu().numpy()
        heatmap = np.maximum(heatmap, 0)
        heatmap /= np.max(heatmap)
        return heatmap

# ------------------
# Setup
# ------------------
print("hi setup")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = models.resnet18(pretrained=False)
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 2)
model.load_state_dict(torch.load("models/resnet18_xray.pth", map_location=device))
model = model.to(device)
model.eval()

#the layer from which the feature map is extracted
target_layer = model.layer4[1].conv2

#creating a gradcame object
gradcam = GradCAM(model, target_layer)

transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# ------------------
# Paths
# ------------------
data_dir = "data/chest_xray/test"
gradcam_dir = "outputs/gradcam"
report_dir = "outputs/reports"
os.makedirs(gradcam_dir, exist_ok=True)
os.makedirs(report_dir, exist_ok=True)

classes = ["NORMAL", "PNEUMONIA"]
qa_chain = get_qa_chain(temperature=0.0)

# ------------------
# Main Loop
# ------------------
for label in classes:
    print("entered main loop")
    folder = os.path.join(data_dir, label)
    for img_name in os.listdir(folder):
        img_path = os.path.join(folder, img_name)
        img = Image.open(img_path).convert("RGB")
        # converts a 224*224 --transform()-->  224*224*3(c*width*height) 
        #--unsqueeze(0)(adds an another dimension at position 0 as a CNN expects the images in minibatches) --> [1, 224, 224, 3] 
        input_tensor = transform(img).unsqueeze(0).to(device)

        # Forward + Backward
        #forward pass through the model -> output[1*2] matrix as we have 2 possible classes
        output = model(input_tensor)
        #chooses the index of the one which has the highest probability (.item() converts the torch tensor to an integer)
        pred_class = torch.argmax(output, 1).item()
        #extracts the actual score for backpropagation
        score = output[0, pred_class]
        #Clears any previous gradients
        model.zero_grad()
        #backward pass (backpropagation) on the predicted score
        score.backward()

        # Generate Grad-CAM heatmap
        heatmap = gradcam.generate_heatmap(pred_class)
        heatmap = cv2.resize(heatmap, (img.size[0], img.size[1]))
        heatmap = np.uint8(255 * heatmap)
        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
        img_np = np.array(img)
        overlay = cv2.addWeighted(img_np, 0.6, heatmap, 0.4, 0)

        # Save overlay
        gradcam_path = os.path.join(gradcam_dir, f"{label}_{img_name}_gradcam.jpg")
        cv2.imwrite(gradcam_path, overlay)
        '''
        '''
        # Generate report using LLM
        prompt = f"""
        A chest X-ray has been classified as {classes[pred_class]}.
        Generate a structured radiology report including:
        findings, impression, and recommendations.
        """
        response = qa_chain.invoke({"query": prompt})
        report_text = _extract_text(response)
        '''
        '''
        print("hi")
        # Run Grad-CAM for localization
        heatmap = gradcam.generate_heatmap(pred_class)

	    # Summarize Grad-CAM findings (location + class)
        summary = gradcam.generate_report(classes[pred_class], heatmap)

        print(summary)
	    # Use LLM to generate full structured radiology report
        report_text = generate_radiology_report(summary, qa_chain)


        # Structure report
        report_obj = PneumoniaInfo(
            symptoms=report_text,
            causes="Refer to LLM report",
            treatments="Refer to LLM report",
            prevention="Refer to LLM report"
        )
        print(report_obj)
        # Save report as JSON (Pydantic v2)
        report_path = os.path.join(report_dir, f"{label}_{img_name}_report.json")
        with open(report_path, "w") as f:
            f.write(report_obj.model_dump_json(indent=2))

        print(f"âœ… Processed {img_name} -> Pred: {classes[pred_class]}")
        print(f"Grad-CAM saved: {gradcam_path}")
        print(f"Report saved: {report_path}")

'''